{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-P-3Nx3OcSnx"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------------------\n",
        "def extract_room_labels(img):\n",
        "    # Create mask of same size as image\n",
        "    mask = np.zeros(img.shape, dtype=np.uint8)\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply adaptive thresholding\n",
        "    threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    # Find contours in binary image\n",
        "    contours, hierarchy = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Draw contours on mask for those within width and height boundaries\n",
        "    for cnt in contours:\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "        if w < 40 and 12 < h < 20:                       # Parameters\n",
        "            cv2.drawContours(mask, [cnt], 0, (255,255,255), 1)\n",
        "\n",
        "    # cv2_imshow(\"mask\", mask)\n",
        "\n",
        "    # Perform dilation on the contoured objects so words can be identified as one and repeat process as above\n",
        "    kernel = np.ones((4,4), np.uint8)                # Variable\n",
        "    dilation = cv2.dilate(mask, kernel, iterations = 1)\n",
        "    gray_d = cv2.cvtColor(dilation, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    threshold_d = cv2.threshold(gray_d, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    contours_d, hierarchy = cv2.findContours(threshold_d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Create copy to show image once texts are removed\n",
        "    text_extracted_img = img.copy()\n",
        "    bounded_text_img = img.copy()\n",
        "\n",
        "    ROI = []\n",
        "    coordinates = []\n",
        "\n",
        "    # Draw rectangle on bounding boxes within width and height boundaries\n",
        "    for cnt in contours_d:\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "        if w > 30 and h > 10:                          # Parameter\n",
        "            cv2.rectangle(bounded_text_img,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "            roi_c = bounded_text_img[y:y+h, x:x+w]\n",
        "            coordinates.append((x, y, w, h))\n",
        "            ROI.append(roi_c)\n",
        "            text_extracted_img[y:y+h, x:x+w] = 255           # Replace the identified text with white color\n",
        "\n",
        "    # plt.figure()\n",
        "    # plt.imshow(bounded_text_img)\n",
        "    # cv2_imshow(bounded_text_img)\n",
        "\n",
        "    # Extract texts from bounding boxes\n",
        "    room_labels = []\n",
        "    for i, room in enumerate(ROI):\n",
        "        text = pytesseract.image_to_string(room, lang=\"eng\", config=\"--psm 6\")   # config\n",
        "        text = text.replace(\"\\n\", ' ')\n",
        "        room_labels.append((text, coordinates[i]))\n",
        "\n",
        "    return room_labels, text_extracted_img\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------------------\n",
        "def fill_wall_gaps(img):\n",
        "    corners_detacted_img = img.copy()\n",
        "    gaps_filled_img = img.copy()\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    thresh= cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    thresh = np.float32(thresh)   # Converted to float32 type for Harris Corner function\n",
        "\n",
        "    # Detect corners here\n",
        "    dst = cv2.cornerHarris(thresh, 3, 7, 0.07)   # Parameter    cv2.cornerHarris(img, blockSize, ksize, k)\n",
        "\n",
        "    dst = cv2.dilate(dst, None)\n",
        "\n",
        "    corners_detacted_img[dst > 0.1 * dst.max()]=[0, 255, 0]      # Show corners in green color\n",
        "\n",
        "    # cv2_imshow(corners_detacted_img)\n",
        "\n",
        "    corners = dst > 0.1 * dst.max()      # Returns an array of image size with boolean values (true == corners)\n",
        "\n",
        "    # Draw horizontal lines from parallel corners\n",
        "    for y, row in enumerate(corners):\n",
        "        x_same_y = np.argwhere(row)\n",
        "        for x1, x2 in zip(x_same_y[:-1], x_same_y[1:]):\n",
        "            if abs(x2[0] - x1[0]) < 70:            # Parameter\n",
        "                color = 0\n",
        "                cv2.line(gaps_filled_img, (int(x1), int(y)), (int(x2), int(y)), color, 1)\n",
        "\n",
        "    # Draw vertical lines from parallel corners\n",
        "    for x, col in enumerate(corners.T):\n",
        "        y_same_x = np.argwhere(col)\n",
        "        for y1, y2 in zip(y_same_x[:-1], y_same_x[1:]):\n",
        "            if abs(y2[0] - y1[0]) < 70:            # Parameter\n",
        "                color = 0\n",
        "                cv2.line(gaps_filled_img, (int(x), int(y1)), (int(x), int(y2)), color, 1)\n",
        "\n",
        "    return gaps_filled_img\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------------------\n",
        "def detect_rooms(gaps_filled_img, text_extracted_img):\n",
        "    segmented_rooms_img = text_extracted_img.copy()\n",
        "\n",
        "    gray = cv2.cvtColor(gaps_filled_img, cv2.COLOR_RGB2GRAY)\n",
        "    thresh= cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    mor_img = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, np.ones((3, 3)), iterations=2)       # Parameter (to remove small objects)\n",
        "\n",
        "    # cv2_imshow(mor_img)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(mor_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # sort the contours in ascending order of area\n",
        "    sorted_contours = sorted(contours, key=cv2.contourArea, reverse=False)\n",
        "\n",
        "    room_coordinates = []\n",
        "    initial_contours = []\n",
        "\n",
        "    img_size = gaps_filled_img.shape[0] * gaps_filled_img.shape[1]\n",
        "\n",
        "    for c in sorted_contours:\n",
        "        area = cv2.contourArea(c)\n",
        "        x, y, w, h = cv2.boundingRect(c) # obtain coordinates of contours\n",
        "        if area > 1000 and area < img_size * 0.5 and w * h < img_size :         # Parameter\n",
        "            color = [random.randrange(0, 255), random.randrange(0, 255), random.randrange(0, 255)]\n",
        "            cv2.fillPoly(segmented_rooms_img, [c], (color[0], color[1], color[2]))        # Show the segmented rooms in random colors\n",
        "            room_coordinates.append((x,y,w,h))\n",
        "            initial_contours.append(c)\n",
        "\n",
        "    return room_coordinates, initial_contours, segmented_rooms_img\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------------------\n",
        "def match_room_and_label(room_labels, initial_contours, img):\n",
        "    final_segmented_rooms_img = img.copy()\n",
        "    final_list = []\n",
        "\n",
        "    # Match room labels to room coordinates\n",
        "    for c in initial_contours:\n",
        "        for label in room_labels:\n",
        "            x, y, w, h = cv2.boundingRect(c)\n",
        "            label_midpoint = [((2*label[1][0]+label[1][2]) / 2), ((2*label[1][1]+label[1][3]) / 2)] # Calculate Midpoint (x, y)\n",
        "            if cv2.pointPolygonTest(c, label_midpoint, False) == 1:           # If midpoint of label is within room boundaries\n",
        "                final_list.append((label[0], (x, y, w, h)))\n",
        "                color = [random.randrange(0, 255), random.randrange(0, 255), random.randrange(0, 255)]\n",
        "                cv2.fillPoly(final_segmented_rooms_img, [c], (color[0], color[1], color[2]))        # Show final segmented rooms in random colors\n",
        "\n",
        "    return final_list, final_segmented_rooms_img\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # file path\n",
        "    input_folder = \"./Input\"\n",
        "    output_folder = \"./Output\"\n",
        "\n",
        "    # Create the output folder\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Processing the file\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\")):  # 只处理图像文件\n",
        "            file_path = os.path.join(input_folder, filename)\n",
        "            print(f\"Processing file: {file_path}\")\n",
        "\n",
        "            # read the image\n",
        "            img = cv2.imread(file_path)\n",
        "            if img is None:\n",
        "                print(f\"Failed to load image: {file_path}\")\n",
        "                continue\n",
        "            # cv2_imshow(img)\n",
        "\n",
        "            # extract room labels from the image\n",
        "            room_labels, text_extracted_img = extract_room_labels(img)\n",
        "            # cv2_imshow(text_extracted_img)\n",
        "            # print(\"room labels: \" + str(room_labels))\n",
        "\n",
        "            # fill gaps in the walls of the image\n",
        "            gaps_filled_img = fill_wall_gaps(text_extracted_img)\n",
        "            # cv2_imshow(gaps_filled_img)\n",
        "\n",
        "            # detect rooms in the image\n",
        "            room_coordinates, initial_contours, segmented_rooms_img = detect_rooms(gaps_filled_img, text_extracted_img)\n",
        "            # cv2_imshow(segmented_rooms_img)\n",
        "            # print(\"\\nrooms coordinates: \" + str(room_coordinates))\n",
        "\n",
        "            # match room labels with their corresponding coordinates\n",
        "            final_list, final_segmented_rooms_img = match_room_and_label(room_labels, initial_contours, text_extracted_img)\n",
        "            # cv2_imshow(final_segmented_rooms_img)\n",
        "            # print(\"\\nfinal output: \" + str(final_list))\n",
        "\n",
        "            # save the result\n",
        "            output_path = os.path.join(output_folder, f\"processed_{filename}\")\n",
        "            cv2.imwrite(output_path, final_segmented_rooms_img)\n",
        "            print(f\"Saved processed image to: {output_path}\")"
      ]
    }
  ]
}